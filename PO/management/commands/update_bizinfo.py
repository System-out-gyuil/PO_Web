import os
import re
import requests
from datetime import datetime
from django.core.management.base import BaseCommand
from board.models import BizInfo
from PO.management.commands.utils import fetch_iframe_src
from config import BIZINFO_API_KEY, CHROME_DRIVER_PATH, OPEN_AI_API_KEY, NAVER_CLOVA_OCR_API_KEY, NAVER_CLOUD_CLOVA_OCR_API_URL
from langchain_openai import ChatOpenAI
import pdfplumber
import uuid
import json
import time
from PIL import Image
import subprocess

class Command(BaseCommand):
    help = "BizInfo API í˜¸ì¶œ ë° DB ì—…ë°ì´íŠ¸"

    def handle(self, *args, **kwargs):
        url = "https://www.bizinfo.go.kr/uss/rss/bizinfoApi.do"
        params = {
            "crtfcKey": BIZINFO_API_KEY,
            "dataType": "json",
            "searchCnt": 100,
            "pageUnit": 20,
            "pageIndex": 3
        }

        try:
            response = requests.get(url, params=params, timeout=30)
            response.raise_for_status()
            items = response.json().get("jsonArray", [])

            for item in items:
                pblanc_id = item.get("pblancId")
                if BizInfo.objects.filter(pblanc_id=pblanc_id).exists():
                    continue

                reception_start = datetime.strptime("19000101", "%Y%m%d").date()
                reception_end = datetime.strptime("99991231", "%Y%m%d").date()
                reception_raw = item.get("reqstBeginEndDe")
                if reception_raw and "~" in reception_raw:
                    try:
                        start_str, end_str = reception_raw.split("~")
                        reception_start = datetime.strptime(start_str.strip(), "%Y%m%d").date()
                        reception_end = datetime.strptime(end_str.strip(), "%Y%m%d").date()
                    except:
                        pass

                creatPnttm = item.get("creatPnttm")
                registered_at = datetime.strptime(creatPnttm, "%Y-%m-%d %H:%M:%S").date() if creatPnttm else None
                iframe_src = fetch_iframe_src(pblanc_id, CHROME_DRIVER_PATH)

                file_url = item.get("printFlpthNm")
                raw_file_name = item.get("printFileNm") or "default.pdf"
                file_name = self.sanitize_filename(raw_file_name)
                text, structured_data = "", {}
                if file_url:
                    try:
                        file_path = self.download_file(file_url, file_name)
                        text = self.extract_text(file_path)
                        structured_data = self.extract_structured_data(text)
                        print("\nğŸ“‚ structured_data:", structured_data)
                        os.remove(file_path)
                    except Exception as e:
                        self.stderr.write(f"íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {file_url} - {e}")

                BizInfo.objects.create(
                    pblanc_id=pblanc_id,
                    title=item.get("pblancNm"),
                    content=item.get("bsnsSumryCn"),
                    registered_at=registered_at,
                    reception_start=reception_start,
                    reception_end=reception_end,
                    institution_name=item.get("jrsdInsttNm"),
                    enroll_method=item.get("reqstMthPapersCn") or "ì‹ ì²­ ë°©ë²•ì€ ê³µê³ ë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”.",
                    target=item.get("trgetNm"),
                    field=item.get("pldirSportRealmLclasCodeNm"),
                    hashtag=item.get("hashtags"),
                    print_file_name=raw_file_name,
                    print_file_path=item.get("printFlpthNm"),
                    company_hall_path=item.get("pblancUrl"),
                    support_field=item.get("pldirSportRealmMlsfcCodeNm"),
                    application_form_name=item.get("fileNm") or "",
                    application_form_path=item.get("flpthNm") or "",
                    iframe_src=iframe_src,
                    employee_count=structured_data.get("ì§ì›ìˆ˜"),
                    revenue=structured_data.get("ë§¤ì¶œê·œëª¨"),
                    noti_summary=structured_data.get("ê³µê³ ë‚´ìš©"),
                    business_period=structured_data.get("ì‚¬ì—…ê¸°ê°„(ì—…ë ¥)"),
                    region=structured_data.get("ì§€ì—­"),
                    possible_industry=structured_data.get("ê°€ëŠ¥ì—…ì¢…"),
                    export_performance=structured_data.get("ìˆ˜ì¶œì‹¤ì ì—¬ë¶€")
                )

            self.stdout.write(self.style.SUCCESS(f"{len(items)}ê±´ ì²˜ë¦¬ ì™„ë£Œ."))

        except Exception as e:
            self.stderr.write(self.style.ERROR(f"ì‹¤íŒ¨: {e}"))

    def sanitize_filename(self, name):
        return re.sub(r"[^\wê°€-í£._]+", "_", name).strip("_")

    def download_file(self, url, file_name):
        response = requests.get(url, stream=True, timeout=15)
        response.raise_for_status()

        save_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..", "files"))
        os.makedirs(save_dir, exist_ok=True)
        save_path = os.path.join(save_dir, file_name)

        with open(save_path, "wb") as f:
            for chunk in response.iter_content(1024):
                f.write(chunk)
        print("ğŸ“‚ save_path:", save_path)
        return save_path

    def is_text_pdf(self, file_path):
        try:
            with pdfplumber.open(file_path) as pdf:
                for page in pdf.pages[:2]:
                    if page.extract_text():
                        return True
            return False
        except:
            return False

    def extract_text(self, file_path):
        full_text = ""
        if file_path.endswith(".pdf"):
            if self.is_text_pdf(file_path):
                with pdfplumber.open(file_path) as pdf:
                    for page in pdf.pages:
                        page_text = page.extract_text()
                        if page_text:
                            full_text += page_text + "\n"
            else:
                return self.clova_ocr(file_path, "pdf")

        elif file_path.endswith(('.jpg', '.jpeg', '.png')):
            return self.clova_ocr(file_path, "jpg")

        elif file_path.endswith(".hwp"):
            pdf_path = self.convert_hwp_to_pdf(file_path)
            return self.extract_text(pdf_path)

        return full_text.strip() or "ì˜¤ë¥˜"

    def clova_ocr(self, file_path, fmt):
        request_json = {
            'images': [{'format': fmt, 'name': 'demo'}],
            'requestId': str(uuid.uuid4()),
            'version': 'V1',
            'timestamp': int(time.time() * 1000)
        }
        payload = {'message': json.dumps(request_json).encode('UTF-8')}
        files = [('file', open(file_path, 'rb'))]
        headers = {'X-OCR-SECRET': NAVER_CLOVA_OCR_API_KEY}
        response = requests.post(NAVER_CLOUD_CLOVA_OCR_API_URL, headers=headers, data=payload, files=files)

        full_text = ""
        for field in response.json()['images'][0].get('fields', []):
            full_text += field['inferText'] + " "
        return full_text.strip()

    def convert_hwp_to_pdf(self, hwp_path):
        output_dir = os.path.dirname(hwp_path)
        try:
            result = subprocess.run([
                "libreoffice",
                "--headless",
                "--convert-to", "pdf:writer_pdf_Export",
                hwp_path,
                "--outdir", output_dir
            ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, timeout=30)

            print("ğŸ“¦ libreoffice stdout:", result.stdout.decode())
            print("ğŸ“› libreoffice stderr:", result.stderr.decode())

            basename = os.path.splitext(os.path.basename(hwp_path))[0] + ".pdf"
            converted_pdf = os.path.join(output_dir, basename)

            if os.path.exists(converted_pdf):
                return converted_pdf
            else:
                print(f"[âŒ ë³€í™˜ ì‹¤íŒ¨] {converted_pdf} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                return ""
        except Exception as e:
            print(f"[ì˜ˆì™¸ ë°œìƒ] HWP â†’ PDF ë³€í™˜ ì‹¤íŒ¨: {e}")
            return ""

    def extract_structured_data(self, text):
        # prompt = (
        #     "ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” ì •ë¶€ ì§€ì›ì‚¬ì—… ê³µê³ ë¬¸ì—ì„œ ì¶”ì¶œëœ ì‹¤ì œ ë‚´ìš©ì…ë‹ˆë‹¤. "
        #     "ì´ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í—ˆêµ¬ ì—†ì´ ì •í™•í•˜ê²Œ ìš”ì•½í•´ì¤˜. ì¶”ê°€ì ì¸ ì¶”ë¡ ì´ë‚˜ ê°€ì •ì€ í•˜ì§€ ë§ê³ , ì›ë¬¸ ê¸°ë°˜ìœ¼ë¡œë§Œ ì‘ì„±í•´ì¤˜.\n\n"
        #     "â€» ë§¤ìš° ì¤‘ìš”: ì„ íƒ ê°€ëŠ¥í•œ ëª¨ë“  ê¸°ì¤€ì—ì„œ ë³µìˆ˜ ì„ íƒì´ ê°€ëŠ¥í•˜ë©°, í•´ë‹¹í•˜ëŠ” ëª¨ë“  í•­ëª©ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n"
        #     "ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ì—…ê¸°ê°„ì´ 3ë…„ ì´ìƒì´ë©´ '3~7ë…„', '7ë…„ ì´ìƒ'ì„ ëª¨ë‘ ì„ íƒí•˜ê³ , ë§¤ì¶œê·œëª¨ê°€ 1ì–µ ì´ìƒ 10ì–µ ì´í•˜ë¼ë©´ '1~5ì–µ', '5~10ì–µ'ì„ ëª¨ë‘ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. ì§ì›ìˆ˜ê°€ 1ì¸ ì´ìƒì´ë¼ë©´ '1~4ì¸', '5ì¸ ì´ìƒ' ì¤‘ í•´ë‹¹í•˜ëŠ” ëª¨ë“  í•­ëª©ì„ ë°˜ë“œì‹œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.\n\n"
        #     "ë§Œì•½ ëª¨ë“  í•­ëª©ì´ í¬í•¨ëœë‹¤ë©´ \'ë¬´ê´€\' í•˜ë‚˜ë§Œ ë„£ì–´ì¤˜"
        #     "ê°€ëŠ¥í•œ ì˜ˆì‹œ ì¤‘ ì‹¤ì œë¡œ ì„ ì •ë  ìˆ˜ ìˆëŠ” ì •í™•í•˜ê³  ì—„ê²©í•œ ê¸°ì¤€ìœ¼ë¡œ ì„ íƒí•´ì¤˜"
        #     "ì•„ë˜ í•­ëª©ë“¤ì„ ì •í™•íˆ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜\n"
        #     "- ì§€ì—­\n"
        #     "- ì§ì›ìˆ˜ : ë¬´ê´€, 1~4ì¸, 5ì¸ ì´ìƒ (ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥, ë§Œì•½ ëª¨ë‘ í•´ë‹¹í•˜ë©´ ë¬´ê´€)\n"
        #     "- ì‚¬ì—…ê¸°ê°„(ì—…ë ¥): ë¬´ê´€, ì˜ˆë¹„ ì°½ì—…, 1ë…„ ì´í•˜, 1~3ë…„, 3~7ë…„, 7ë…„ ì´ìƒ (í•´ë‹¹ë˜ëŠ” ëª¨ë“  í•­ëª©ì„ ë³µìˆ˜ ì„ íƒ, ì˜ˆ: ì—…ë ¥ì´ 3ë…„ ì´ìƒì´ë©´ '3~7ë…„', '7ë…„ ì´ìƒ'ì„ ë°˜ë“œì‹œ ëª¨ë‘ í¬í•¨)\n"
        #     "- ë§¤ì¶œê·œëª¨: ë¬´ê´€, 1ì–µ ì´í•˜, 1~5ì–µ, 5~10ì–µ, 10~30ì–µ, 30ì–µ ì´ìƒ (í•´ë‹¹ë˜ëŠ” ëª¨ë“  í•­ëª©ì„ ë³µìˆ˜ ì„ íƒ, ì˜ˆ: ë§¤ì¶œì´ 1ì–µ ì´ìƒ 10ì–µ ì´í•˜ë¼ë©´ '1~5ì–µ', '5~10ì–µ'ì„ ë°˜ë“œì‹œ ëª¨ë‘ í¬í•¨)\n"
        #     "- ê°€ëŠ¥ì—…ì¢…: ì œì¡°ì—…, ì„œë¹„ìŠ¤ì—…, ìš”ì‹ì—…, IT, ë„ì†Œë§¤, ê±´ì„¤ì—…, ë¬´ì—­ì—…, ìš´ìˆ˜ì—…, ë†ìˆ˜ì‚°ì—…, ë¯¸ë””ì–´ (í•´ë‹¹ë˜ëŠ” ëª¨ë“  í•­ëª©ì„ ë³µìˆ˜ ì„ íƒ)\n"
        #     "- ìˆ˜ì¶œì‹¤ì ì—¬ë¶€: ë¬´ê´€, ìˆ˜ì¶œê¸°ì—…, ìˆ˜ì¶œ í¬ë§ ì¤‘ í•˜ë‚˜ ì´ìƒ ì„ íƒ (í•´ë‹¹ë˜ëŠ” ëª¨ë“  í•­ëª©ì„ ë³µìˆ˜ ì„ íƒ)\n"
        #     "- ê³µê³ ë‚´ìš©: ìµœì†Œ 450ì ì´ìƒ, ì›ë¬¸ ê¸°ë°˜ ìš”ì•½\n\n"
        # ) + text
        prompt = (

                "ì•„ë˜ í…ìŠ¤íŠ¸ëŠ” ì •ë¶€ ì§€ì›ì‚¬ì—… ê³µê³ ë¬¸ì—ì„œ ì¶”ì¶œëœ ì‹¤ì œ ë‚´ìš©ì…ë‹ˆë‹¤. ì´ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ í—ˆêµ¬ ì—†ì´ ì •í™•í•˜ê²Œ ìš”ì•½í•´ì¤˜. ì¶”ê°€ì ì¸ ì¶”ë¡ ì´ë‚˜ ê°€ì •ì€ í•˜ì§€ ë§ê³ , ì›ë¬¸ì— ì§ì ‘ ëª…ì‹œëœ ë‚´ìš©ì„ ì—„ê²©í•˜ê²Œ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±í•´ì¤˜."

                "â€» ë§¤ìš° ì¤‘ìš”: ì•„ë˜ ê¸°ì¤€ë“¤ì€ ì‹¤ì œ ê³µê³ ë¬¸ì—ì„œ ëª…í™•í•˜ê²Œ ìš”êµ¬í•˜ê±°ë‚˜ ëª…ì‹œëœ ì¡°ê±´ì— ë§ì¶° ì •í™•í•˜ê³  ì—„ê²©í•˜ê²Œ ì„ ì •í•´ì•¼ í•©ë‹ˆë‹¤. ê° ê¸°ì¤€ì€ í•´ë‹¹ë˜ëŠ” ëª¨ë“  í•­ëª©ì„ ë³µìˆ˜ë¡œ ì„ íƒí•  ìˆ˜ ìˆìœ¼ë©°, ì›ë¬¸ì—ì„œ ëª…ì‹œì ìœ¼ë¡œ í•´ë‹¹ ì¡°ê±´ì´ ë‚˜íƒ€ë‚˜ì§€ ì•Šìœ¼ë©´ ì•„ë˜ ë°©ë²•ì„ ë”°ë¥´ì„¸ìš”."

                "1) ì›ë¬¸ì—ì„œ ì¡°ê±´ì´ ëª…ì‹œì ìœ¼ë¡œ ë‚˜íƒ€ë‚œ ê²½ìš°:"
                "- ì‚¬ì—…ê¸°ê°„(ì—…ë ¥)ì´ 'ìµœì†Œ', 'ì´ìƒ' ë“±ìœ¼ë¡œ í‘œí˜„ë˜ë©´ ëª¨ë“  ê°€ëŠ¥í•œ ë²”ìœ„ë¥¼ ì„ íƒ (ì˜ˆ: 'ì—…ë ¥ 3ë…„ ì´ìƒ'ì´ë©´ '3~7ë…„', '7ë…„ ì´ìƒ' ëª¨ë‘ ì„ íƒ)."
                "- ë§¤ì¶œê·œëª¨ê°€ 'ìµœì†Œ', 'ì´ìƒ', 'ì´í•˜' ë“±ìœ¼ë¡œ í‘œí˜„ë˜ì—ˆìœ¼ë©´ í•´ë‹¹ ë²”ìœ„ ë‚´ ëª¨ë“  ë§¤ì¶œ êµ¬ê°„ì„ ë³µìˆ˜ ì„ íƒ."
                "- ì§ì›ìˆ˜ê°€ 'ì´ìƒ' ë“±ìœ¼ë¡œ í‘œí˜„ë˜ë©´ í•´ë‹¹ë˜ëŠ” ëª¨ë“  ì§ì› ìˆ˜ ë²”ìœ„ë¥¼ ì„ íƒ."

                "2) ì›ë¬¸ì—ì„œ ëª…í™•í•œ ê¸°ì¤€ì´ ë‚˜íƒ€ë‚˜ì§€ ì•Šì€ ê²½ìš°:"
                "- ì§€ì›ë‚´ìš©ì˜ ë‚œì´ë„, ì§€ì› ê·œëª¨, ëª¨ì§‘ ê¸°ì—… ìˆ˜ ë“±ì„ ì¢…í•©ì ìœ¼ë¡œ íŒë‹¨í•˜ì—¬ ì‹¤ì œë¡œ ì„ ì • ê°€ëŠ¥ì„±ì´ ë†’ì€ ì—„ê²©í•œ ê¸°ì¤€ë§Œ ì„ íƒ."

                "â€» ëª¨ë“  ì—…ì²´ê°€ ì§€ì› ê°€ëŠ¥í•˜ë©´ 'ë¬´ê´€'ë§Œ ì„ íƒí•©ë‹ˆë‹¤."

                "ì•„ë˜ í•­ëª©ë“¤ì„ ì •í™•íˆ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜:"

                "- ì§€ì—­: ì›ë¬¸ì—ì„œ ì§€ì› ê°€ëŠ¥ ì§€ì—­ì„ ì •í™•íˆ ì„ íƒí•˜ê³ , ì œí•œì´ ì—†ìœ¼ë©´ 'ë¬´ê´€'."
                "- ì§ì›ìˆ˜: ë¬´ê´€, 1~4ì¸, 5ì¸ ì´ìƒ ì¤‘ ì‹¤ì œë¡œ ì„ ì •ë  ê°€ëŠ¥ì„±ì´ ë†’ì€ ì—„ê²©í•œ ê¸°ì¤€ë§Œ ì„ íƒ."
                "- ì‚¬ì—…ê¸°ê°„(ì—…ë ¥): ë¬´ê´€, ì˜ˆë¹„ ì°½ì—…, 1ë…„ ì´í•˜, 1~3ë…„, 3~7ë…„, 7ë…„ ì´ìƒ ì¤‘ ì‹¤ì œë¡œ ì„ ì •ë  ê°€ëŠ¥ì„±ì´ ë†’ì€ ì—„ê²©í•œ ê¸°ì¤€ë§Œ ì„ íƒ."
                "- ë§¤ì¶œê·œëª¨: ë¬´ê´€, 1ì–µ ì´í•˜, 1~5ì–µ, 5~10ì–µ, 10~30ì–µ, 30ì–µ ì´ìƒ ì¤‘ ì‹¤ì œë¡œ ì„ ì •ë  ê°€ëŠ¥ì„±ì´ ë†’ì€ ì—„ê²©í•œ ê¸°ì¤€ë§Œ ì„ íƒ."
                "- ê°€ëŠ¥ì—…ì¢…: ì œì¡°ì—…, ì„œë¹„ìŠ¤ì—…, ìš”ì‹ì—…, IT, ë„ì†Œë§¤, ê±´ì„¤ì—…, ë¬´ì—­ì—…, ìš´ìˆ˜ì—…, ë†ìˆ˜ì‚°ì—…, ë¯¸ë””ì–´ ì¤‘ ì‹¤ì œë¡œ ì„ ì •ë  ê°€ëŠ¥ì„±ì´ ë†’ì€ ì—„ê²©í•œ ê¸°ì¤€ë§Œ ì„ íƒ (ëª¨ë“  ì—…ì¢… ê°€ëŠ¥ ì‹œ 'ë¬´ê´€')."
                "- ìˆ˜ì¶œì‹¤ì ì—¬ë¶€: ë¬´ê´€, ìˆ˜ì¶œê¸°ì—…, ìˆ˜ì¶œ í¬ë§ ì¤‘ ì‹¤ì œë¡œ ì„ ì •ë  ê°€ëŠ¥ì„±ì´ ë†’ì€ ì—„ê²©í•œ ê¸°ì¤€ë§Œ ì„ íƒ."
                "- ê³µê³ ë‚´ìš©: ë°˜ë“œì‹œ ìµœì†Œ 450ì ì´ìƒìœ¼ë¡œ ì›ë¬¸ì„ ì •í™•íˆ ìš”ì•½í•˜ê³ , ì›ë¬¸ì˜ ì£¼ìš” ì„ ì •ê¸°ì¤€, ì§€ì›ë‚´ìš©, ì§€ì›ê·œëª¨, ì‹ ì²­ë°©ë²• ë“±ì„ ë¹ ì§ì—†ì´ ìƒì„¸íˆ í¬í•¨í•©ë‹ˆë‹¤"
            ) + text
                 

        llm = ChatOpenAI(temperature=0, model_name='gpt-4o-mini', openai_api_key=OPEN_AI_API_KEY)
        try:
            response = llm.invoke(prompt)
            return self.clean_json_from_response(getattr(response, "content", "").strip())
        except Exception as e:
            print(f"[GPT ì˜¤ë¥˜] {e}")
            return {"ì§ì›ìˆ˜": "ì˜¤ë¥˜", "ë§¤ì¶œê·œëª¨": "ì˜¤ë¥˜", "ê³µê³ ë‚´ìš©": "ì˜¤ë¥˜"}

    def clean_json_from_response(self, content: str) -> dict:
        try:
            match = re.search(r"```(?:json)?\\s*(\{.*?\})\\s*```", content, re.DOTALL)
            if match:
                return json.loads(match.group(1))
            match2 = re.search(r"(\{.*?\})", content, re.DOTALL)
            if match2:
                return json.loads(match2.group(1))
            print("âš ï¸ JSON ë¸”ë¡ ì¶”ì¶œ ì‹¤íŒ¨")
            print("ğŸ“„ ì›ë³¸ content:", content)
            return {}
        except Exception as e:
            print(f"[JSON íŒŒì‹± ì˜¤ë¥˜] {e}")
            return {}
